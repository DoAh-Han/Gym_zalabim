{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, silhouette_samples, silhouette_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import requests\n",
    "import pprint\n",
    "import xgboost\n",
    "import scipy\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 지수 형태의 실수를 소수점 3자리까지 표기\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "\n",
    "# 공유 폴더 경로\n",
    "dirShare = \"..\"\n",
    "\n",
    "# 경고 출력 무시\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 버전 확인\n",
    "print(\"Python 현재 버전 : \" + sys.version)\n",
    "print(\"pandas 현재 버전 : \" + pd.__version__)\n",
    "print(\"scikit-learn 현재 버전 : \" + sklearn.__version__)\n",
    "print(\"scipy 현재 버전 : \"+ scipy.__version__)\n",
    "print(\"statsmodels 현재 버전 : \" + statsmodels.__version__)\n",
    "print(\"xgboost 현재 버전 : \" + xgboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오고 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.csv 데이터 프레임으로 불러오기\n",
    "df = pd.read_csv(dirShare+\"/data/train.csv\")\n",
    "\n",
    "# # df 정보 확인\n",
    "# df.info()\n",
    "\n",
    "# # df 상위 10개 불러오기\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(dirShare+\"/data/test.csv\")\n",
    "\n",
    "# df_t.info()\n",
    "# df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 개수 확인하기\n",
    "print(\"train 데이터 개수 : \", df.shape[0])\n",
    "print(\"test 데이터 개수 : \", df_t.shape[0])\n",
    "\n",
    "# len(df)를 써도 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 형식의 컬럼의 기술통계값을 출력, train.csv\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자 형식의 컬럼의 기술통계값을 출력, test.csv\n",
    "df_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼별 null 값 확인하기, train.csv\n",
    "df.shape[0] - df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼별 null 값 확인하기, test.csv\n",
    "df_t.shape[0] - df_t.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employee 컬럼이 object 타입이고, 숫자에 ','이 포함돼 있어 정규 표현식으로 없앰\n",
    "for i in range(2) : \n",
    "    df_t[\"employee\"+str(i+1)] = df_t[\"employee\"+str(i+1)].map(lambda x: re.sub(r\"[^0-9.-]\", \"\", str(x)))\n",
    "\n",
    "df_t[[\"employee1\", \"employee2\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실수 타입으로 변경\n",
    "df_t[\"employee1\"].replace(\"\", np.NaN, inplace=True)\n",
    "df_t[\"employee2\"].replace(\"\", np.NaN, inplace=True)\n",
    "df_t[[\"employee1\", \"employee2\"]] = df_t[[\"employee1\", \"employee2\"]].astype(\"float64\")\n",
    "df_t[[\"employee1\", \"employee2\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t[[\"employee1\", \"employee2\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개/폐업 수 확인\n",
    "df[\"OC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test를 일시적으로 합침\n",
    "df_merge = pd.concat(objs=[df,df_t], axis=0)\n",
    "print(\"합친 데이터 수 : \",len(df_merge))\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아직 운영 중인 병원을 1로 변환\n",
    "df_merge.replace({\"open\":1},inplace=True)\n",
    "# 폐업한 병원을 0으로 변환\n",
    "df_merge.replace({\" close\":0}, inplace=True)\n",
    "# unique() 메서드를 통해 \"OC\" 컬럼의 데이터를 확인\n",
    "# df[\"OC\"].unique()\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오너 변환 여부\n",
    "df_merge[\"ownerChange\"].replace({\"same\":0},inplace=True)\n",
    "df_merge[\"ownerChange\"].replace({\"change\":1},inplace=True)\n",
    "# df[\"ownerChange\"].unique()\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge[\"instkind\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영업이익 컬럼 추가(매출액 - 매출원가 - 판매 관리비 - 급여)\n",
    "# revenue - salescost - sga - salary\n",
    "\n",
    "for i in range(2) : \n",
    "    df_merge.insert(loc=(24*(i)+11), column=\"busiProfit\"+str(i+1), value=(df_merge[\"revenue\"+str(i+1)]-df_merge[\"salescost\"+str(i+1)]-df_merge[\"sga\"+str(i+1)]-df_merge[\"salary\"+str(i+1)]))\n",
    "\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병원 종류 별 병상 수의 차이\n",
    "df_bed = df_merge.groupby(\"instkind\",axis=0)[\"bedCount\"].count()\n",
    "df_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병원의 병상 수가 많으면 그만큼 환자 수용 수가 많으니 병원 서비스가 더 좋아지는 것이 아닐까?\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "plt.figure(figsize=(12,8))\n",
    "    \n",
    "plt.bar(x=df_bed.index, height=df_bed, color=\"#009933\")\n",
    "plt.title(\"병원 종류별 병상 수\")\n",
    "plt.xlabel(\"병원 종류\")\n",
    "plt.ylabel(\"병상 갯수\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개업한 날짜는 변수로서 의미가 없음. 모델은 날짜를 인식하지 못하기 때문에\n",
    "# 개업 날짜와 폐업 날짜의 차이로 변수를 조정할 필요가 있음\n",
    "\n",
    "date_of_2018 = \"2018-01-01\"\n",
    "\n",
    "# 문자 타입을 date 타입으로\n",
    "\n",
    "# df[\"openDate\"] = df[\"openDate\"].apply(lambda x : datetime.strptime(str(x), \"%Y%m%d\")) # ValueError: unconverted data remains: .0\n",
    "df_merge[\"openDate\"] = pd.to_datetime(df_merge[\"openDate\"], format=\"%Y%m%d\")\n",
    "\n",
    "# 날짜 차이를 새로운 컬럼으로 생성, 데이터 프레임 중간에 삽입\n",
    "df_merge.insert(2, \"dif_date\", datetime.strptime(date_of_2018,\"%Y-%m-%d\")-df_merge[\"openDate\"])\n",
    "df_merge[\"dif_date\"] = df_merge[\"dif_date\"].dt.days\n",
    "\n",
    "df_merge.drop(labels=\"openDate\", axis=1, inplace=True)\n",
    "\n",
    "df_merge[\"dif_date\"].tail()\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병원의 종류를, get_dummies를 이용해 one-hot-encoding\n",
    "df_m = pd.get_dummies(df_merge, columns=[\"instkind\"], prefix=[\"instkind\"], prefix_sep=\"_\", dtype=int)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어로 돼 있는 '시도'를 한글로 변환\n",
    "\n",
    "df_m[\"sido\"].replace(['choongnam', 'gyeongnam', 'gyeonggi', 'incheon', 'busan',\n",
    "       'jeonnam', 'seoul', 'jeonbuk', 'choongbuk', 'ulsan', 'daejeon',\n",
    "       'daegu', 'gyeongbuk', 'gangwon', 'gwangju', 'sejong', 'jeju'], \n",
    "       [\"충청남도\", \"경상남도\", \"경기도\", \"인천광역시\", '부산광역시', '전라남도', '서울특별시', \n",
    "        '전라북도', '충청북도', '울산광역시', '대전광역시', '대구광역시', \"경상북도\", \"강원도\", \"광주광역시\", \"세종특별자치시\", '제주특별자치도'],inplace=True)\n",
    "\n",
    "print(\"df_new의 시도 : \",df_m[\"sido\"].unique())\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시도 데이터를 one-hot-encoding\n",
    "df_m = pd.get_dummies(df_m, columns=[\"sido\"], prefix=[\"sido\"], prefix_sep=\"_\", dtype=int)\n",
    "df_m.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.drop(\"sgg\",axis=1,inplace=True)\n",
    "df_m.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분석 1. 결측치 안 채우고 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인구 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017년 지역별 인구수 데이터\n",
    "# https://kosis.kr/statHtml/statHtml.do?orgId=101&tblId=DT_1B040A3\n",
    "pop = pd.read_csv(dirShare+\"/data/행정구역_시군구_별__성별_인구수_20230718231833.csv\", header=1, encoding=\"cp949\")\n",
    "pop.info()\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명을 영어로 바꾸기\n",
    "pop.rename(columns={\"총인구수 (명)\":\"tt_pop\", \"남자인구수 (명)\":\"male_pop\", \"여자인구수 (명)\":\"female_pop\"}, inplace=True)\n",
    "pop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df와 pop(인구수) join\n",
    "df_new = pd.merge(df_m, pop, how=\"inner\", left_on=\"sido\", right_on=\"행정구역(시군구)별\")\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시도를 one-hot-encoding\n",
    "df_new = pd.get_dummies(df_new, columns=[\"sido\"], prefix=[\"sido\"], prefix_sep=\"_\", dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역을 one-hot-encoding 했으므로 시군구 컬럼은 무의미\n",
    "df_new.drop(columns=[\"행정구역(시군구)별\",\"sgg\"], axis=1, inplace=True)\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dvd_test1 = pd.merge(left=df_new, right=df_t[\"inst_id\"], how=\"inner\", on=\"inst_id\")\n",
    "\n",
    "df_dvd_train1 = pd.merge(left=df_new, right=df_t[\"inst_id\"], how=\"outer\", on=\"inst_id\", indicator=True)\n",
    "df_dvd_train1 = df_dvd_train1[df_dvd_train1[\"_merge\"]==\"left_only\"].iloc[:,:df_dvd_train1.shape[1]-1]\n",
    "\n",
    "df_new = pd.concat([df_dvd_train1, df_dvd_test1], axis=0)\n",
    "\n",
    "df_new.iloc[301:310,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans를 통한 병원 세그먼트 군집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_silhouette(cluster_lists, X_features): \n",
    "\n",
    "    \"\"\"\n",
    "    함수 출처 : https://dev-ryuon.tistory.com/83\n",
    "    \"\"\"\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "    import math\n",
    "\n",
    "    # 입력값으로 클러스터링 갯수들을 리스트로 받아서, 각 갯수별로 클러스터링을 적용하고 실루엣 개수를 구함\n",
    "    n_cols = len(cluster_lists)\n",
    "\n",
    "    # plt.subplots()으로 리스트에 기재된 클러스터링 수만큼의 sub figures를 가지는 axs 생성 \n",
    "    fig, axs = plt.subplots(figsize=(4*n_cols, 4), nrows=1, ncols=n_cols)\n",
    "\n",
    "    # 리스트에 기재된 클러스터링 갯수들을 차례로 iteration 수행하면서 실루엣 개수 시각화\n",
    "    for ind, n_cluster in enumerate(cluster_lists):\n",
    "\n",
    "        # KMeans 클러스터링 수행하고, 실루엣 스코어와 개별 데이터의 실루엣 값 계산. \n",
    "        clusterer = KMeans(n_clusters = n_cluster, max_iter=500, random_state=100)\n",
    "        cluster_labels = clusterer.fit_predict(X_features)\n",
    "\n",
    "        sil_avg = silhouette_score(X_features, cluster_labels)\n",
    "        sil_values = silhouette_samples(X_features, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        axs[ind].set_title('Number of Cluster : '+ str(n_cluster)+'\\n' \\\n",
    "                          'Silhouette Score :' + str(round(sil_avg,3)) )\n",
    "        axs[ind].set_xlabel(\"The silhouette coefficient values\")\n",
    "        axs[ind].set_ylabel(\"Cluster label\")\n",
    "        axs[ind].set_xlim([-0.1, 1])\n",
    "        axs[ind].set_ylim([0, len(X_features) + (n_cluster + 1) * 10])\n",
    "        axs[ind].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        axs[ind].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 클러스터링 갯수별로 fill_betweenx( )형태의 막대 그래프 표현. \n",
    "        for i in range(n_cluster):\n",
    "            ith_cluster_sil_values = sil_values[cluster_labels==i]\n",
    "            ith_cluster_sil_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_sil_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_cluster)\n",
    "            axs[ind].fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_sil_values, \\\n",
    "                                facecolor=color, edgecolor=color, alpha=0.7)\n",
    "            axs[ind].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "            y_lower = y_upper + 10\n",
    "\n",
    "        axs[ind].axvline(x=sil_avg, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_new.iloc[:, 2:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN 값이 없는 컬럼만 남기고, 지역 데이터 없애기\n",
    "df_kmeans = df_new.dropna(axis=1, how=\"any\")\n",
    "# df_kmeans = df_kmeans.iloc[:, :11]\n",
    "df_kmeans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler()\n",
    "\n",
    "df_mmsc = df_kmeans.drop(columns=[\"inst_id\"])\n",
    "\n",
    "df_mmsc.dropna(how=\"any\", axis=1, inplace=True)\n",
    "\n",
    "df_mmsc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalerX1 = scaler1.fit(df_mmsc)\n",
    "\n",
    "X_mmsc1 = scaler1.transform(df_mmsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette([10,12,15,16,18,20,25], X_mmsc1)\n",
    "# 25개가 됐을 때 실루엣 계수가 0.703으로 최대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clst_kmeans = KMeans(n_clusters=25, random_state=100, max_iter=500)\n",
    "\n",
    "model = clst_kmeans.fit(X_mmsc1)\n",
    "clst_label = model.labels_\n",
    "\n",
    "print(clst_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans[\"NumberOfCluster\"] = pd.Series(clst_label)\n",
    "df_kmeans.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재무 정보가 포함돼 있는 데이터 프레임에 클러스터링 넘버 삽입\n",
    "df_join_clst = pd.merge(df_new, df_kmeans[[\"inst_id\", \"NumberOfCluster\"]], how=\"left\", left_on=\"inst_id\", right_on=\"inst_id\")\n",
    "df_join_clst.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 히스토그램 확인\n",
    "\n",
    "def sp_hist(DF=None, colClst=None, colhist=None, Range=None) :\n",
    "    \"\"\"\n",
    "    군집별 특정 컬럼의 히스토그램을 확인합니다.\n",
    "\n",
    "    DF : 히스토그램을 확인하고자 하는 데이터프레임\n",
    "    colClst : 군집 번호를 표시하는 컬럼\n",
    "    colhist : 히스토그램으로 표현하고자 하는 컬럼\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(16, 32), nrows=4, ncols=3)\n",
    "    # axs는 numpy ndarray 형식\n",
    "\n",
    "    # 한글 폰트 설정 및 깨짐 방지\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    for c in range(Range):\n",
    "        dataframe = DF[DF[colClst]==c][colhist]\n",
    "        # print(\"현재 순서 :\",c)\n",
    "        # print(\"행 :\", c//3)\n",
    "        # print(\"열 :\", c%3)\n",
    "        axs[(c//3),(c % 3)].hist(dataframe, bins=20)\n",
    "        axs[(c//3),(c % 3)].set_title('Number of Cluster : '+ str(c)+'\\n' \\\n",
    "                            'Column Name :' + str(dataframe.name) )\n",
    "        axs[(c//3),(c % 3)].set_xlabel(\"계급\")\n",
    "        axs[(c//3),(c % 3)].set_ylabel(\"도수\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 boxplot 확인\n",
    "def sp_boxplot(DF=None, colClst=None, colbox=None, Range=None) :\n",
    "    plt.figure(figsize=(28,20))\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    # rectangular box plot\n",
    "    DF_box = pd.DataFrame()\n",
    "\n",
    "    for c in range(Range) : \n",
    "        dataframe = DF[DF[colClst]==c][colbox]\n",
    "        dataframe.rename(str(c), inplace=True)\n",
    "        DF_box = pd.concat([DF_box, dataframe], axis=1)\n",
    "\n",
    "    sns.boxplot(\n",
    "                data = DF_box,\n",
    "                orient='v'\n",
    "                ) \n",
    "    plt.title(\"클러스터 별 boxplot\")\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_boxplot(DF=df_join_clst, colClst=\"NumberOfCluster\", colbox=\"profit1\", Range=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 중앙값으로 결측치 채움\n",
    "\n",
    "def fill_median(DF=None, colClst=None, colFill=None, numclst=None) :\n",
    "    \"\"\"\n",
    "    결측치가 있는 행 데이터에, 군집별 중앙값을 채워 넣고자 함\n",
    "\n",
    "    DF : 히스토그램을 확인하고자 하는 데이터프레임\n",
    "    colClst : 군집 번호를 표시하는 컬럼(str)\n",
    "    colFill : 결측치를 채우고자 하는 컬럼 리스트(list)\n",
    "    numclst : 클러스터 개수(int)\n",
    "    \"\"\"\n",
    "    for cl in range(numclst) :\n",
    "        for L in colFill :\n",
    "            median_value = DF.loc[DF[colClst] == cl, L].median()\n",
    "            DF.loc[(DF[colClst] == cl) & DF[L].isnull(), L] = median_value\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_clst = fill_median(DF=df_join_clst, colClst=\"NumberOfCluster\", \n",
    "                           colFill=df_join_clst.columns[2:57], numclst=25)\n",
    "df_join_clst.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statsmodels를 사용한 vif 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병원 개/폐업 정보의 다중 회귀 분석과 검정 통계량 확인\n",
    "Models1 = sm.ols(\"OC ~ \" + \"+\".join(df_join_clst.columns[2:84]), data=df_join_clst.iloc[:,1:84])\n",
    "result1 = Models1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수 X와 종속변수 y로 분리\n",
    "X = df_join_clst.iloc[:,2:84]\n",
    "y = df_join_clst.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수들간 다중 공선성 확인, vif 지수 10 이상이면 변수 제거 고려\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values,i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "vif = vif.sort_values(\"VIF Factor\").reset_index(drop=True)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif 지수가 10미만인 컬럼명\n",
    "vif[vif[\"VIF Factor\"]<10.0][\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_vif = vif[vif[\"VIF Factor\"]<10.0][\"features\"]\n",
    "\n",
    "fvList = [feat_vif[f] for f in range(len(feat_vif))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvList.insert(0, \"OC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_vif = df_join_clst[fvList]\n",
    "df_drop_vif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_vif.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models2 = sm.ols(\"OC ~ \" + \"+\".join(df_drop_vif.columns[1:]), data=df_drop_vif)\n",
    "result2 = Models2.fit()\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "vif 지수가 10 이상이라고 무조건 제거하면 안 됨!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD를 위한 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 양은 독립변수 수의 3배 이상은 돼야 함.\n",
    "독립변수로 작용하는 컬럼 수가 57개이므로 다중 공선성과 과적합, 차원의 저주의 영향이 예상되므로\n",
    "차원 축소 필요  \n",
    "  \n",
    "여러 특성들로 구성된 다차원의 데이터 셋의 차원을 축소해 새로운 차원의 데이터 세트를 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_origin = df_join_clst.iloc[:,:57]\n",
    "df_model_origin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수 컬럼 샤피로 윌크 검정으로 정규성 확인\n",
    "# H0 : 변수는 정규성을 따른다.\n",
    "# H1 : 변수는 정규성을 따르지 않는다.\n",
    "\n",
    "cnt = 0\n",
    "for i in range(df_model_origin.shape[1]) : \n",
    "    cnt += 1\n",
    "    shapiro_tt = stats.shapiro(df_model_origin.iloc[:,i])\n",
    "    print(cnt)\n",
    "    if shapiro_tt[1] > 0.05 : \n",
    "        print(\"유의수준 5%에서\")\n",
    "        print(\"컬럼명 \",df_model_origin.columns[i],\"는(은) 귀무가설을 채택, 정규성을 따른다고 가정할 수 있습니다.\")\n",
    "    else : \n",
    "        print(\"유의수준 5%에서\")\n",
    "        print(\"컬럼명 \",df_model_origin.columns[i],\"는(은) 귀무가설을 기각, 정규성을 따른다고 가정할 수 없습니다.\")\n",
    "    print(\"-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))    # 그래프 사이즈 지정\n",
    "stats.probplot(df_model_origin.iloc[:,15], dist=stats.norm, plot=plt) #Sample은 어느 정도 어긋났는지 비교할 분포,\n",
    "                                                  #dist는 기준이 되는 분포, 정규 분포가 아니어도 된다.\n",
    "                                                  #plot은 주로 matplotlib.plt 객체 사용\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD를 통해, A라는 임의의 행렬을 여러개의 A 행렬과 동일한 크기를 갖는 여러개의 행렬로 분해해서 생각할 수 있는데, 분해된 각 행렬의 원소의 값의 크기는 σ의 값의 크기에 의해 결정된다.  \n",
    "다시 말해, SVD를 이용해 임의의 행렬 A를 정보량에 따라 여러 layer로 쪼개서 생각할 수 있게 해준다.  \n",
    "데이터 세트가 스케일링으로 데이터 중심이 동일해지면 사이킷런의 SVD와 PCA는 동일한 변환을 수행하며, 희소 행렬(Sparse Matrix)에 대한 변환도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터의 inst_id가 같은 데이터만 추출\n",
    "df_dvd_test = pd.merge(left=df_model_origin, right=df_t[\"inst_id\"], how=\"inner\", on=\"inst_id\")\n",
    "df_dvd_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터의 inst_id가 다른 데이터만 추출 >> train 데이터\n",
    "# indicator=True는 merge된 각 행의 정보를 알려줌\n",
    "# left에만 존재하는 행이라면 left_only\n",
    "# right에만 존재하는 행이라면 right_only\n",
    "# 둘 다 존재하면 both\n",
    "df_dvd_train = pd.merge(left=df_model_origin, right=df_t[\"inst_id\"], how=\"outer\", on=\"inst_id\", indicator=True)\n",
    "df_dvd_train = df_dvd_train[df_dvd_train[\"_merge\"]==\"left_only\"].iloc[:,:df_dvd_train.shape[1]-1]\n",
    "df_dvd_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_origin = pd.concat([df_dvd_train, df_dvd_test], axis=0)\n",
    "df_model_origin.iloc[301:310, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_origin[df_model_origin[\"OC\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_origin.iloc[:,-55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "scalerX2 = scaler2.fit(df_model_origin.iloc[:,-55:])\n",
    "\n",
    "X_mmsc2 = scaler2.transform(df_model_origin.iloc[:,-55:])\n",
    "\n",
    "X_mmsc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 차원 축소를 위한 SVD 수행\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "make_svd = svd.fit(X_mmsc2)\n",
    "X_svd = svd.transform(X_mmsc2)\n",
    "X_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svd 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 모델의 학습용 데이터와 테스트 데이터를 'train_test_split' 메서드를 통해 분리합니다.  \n",
    "데이터를 무작위로 분리하고 종속 변수의 수가 일정하지 않을 때 종속 변수 비율에 맞춰서 분리해 주기 때문입니다.🫡  \n",
    "하지만 우리는 처음부터 train.csv와 test.csv로 나눠져 있었기 때문에  \n",
    "처음 그대로 나눠야 합니다!⌨️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_origin = X_svd[:301]\n",
    "X_test_origin = X_svd[301:]\n",
    "print(\"학습용 독립변수의 shape : \",X_train_origin.shape)\n",
    "print(\"테스트 독립변수의 shape : \",X_test_origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_origin = df_model_origin.iloc[:301,1]\n",
    "y_test_origin = df_model_origin.iloc[301:,1]\n",
    "print(\"학습용 종속변수의 shape : \",y_train_origin.shape)\n",
    "print(\"테스트 종속변수의 shape : \",y_test_origin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_origin, y_train_origin, test_size=0.3,random_state=100, stratify=y_train_origin)\n",
    "print(\"train 독립변수 크기 : \", X_train.shape)\n",
    "print(\"test 독립변수 크기 : \", X_test.shape)\n",
    "print(\"train 종속변수 크기 : \", y_train.shape)\n",
    "print(\"test 종속변수 크기 : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier()\n",
    "xgb_model = model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "# y_pred_prob = xgb_model.predict_proba(X_test)[:1]\n",
    "print(\"정확도 : \",accuracy_score(y_test, y_pred))\n",
    "print(\"f1 socre : \",f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_r = XGBClassifier(n_estimators=100,\n",
    "                            max_depth = 3,\n",
    "                            grow_policy='lossguide',\n",
    "                            learning_rate=0.5,\n",
    "                            min_child_weight=1,\n",
    "                            reg_lambda=1)\n",
    "xgb_model_r = model_xgb_r.fit(X_train, y_train)\n",
    "\n",
    "y_pred_r = xgb_model_r.predict(X_test)\n",
    "# y_pred_prob = xgb_model.predict_proba(X_test)[:1]\n",
    "print(\"정확도 : \",accuracy_score(y_test, y_pred_r))\n",
    "print(\"f1 socre : \",f1_score(y_test, y_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_originX = X_mmsc2[:301]\n",
    "X_test_originX = X_mmsc2[301:]\n",
    "\n",
    "print(\"svd를 하지 않은 학습용 독립변수의 shape : \",X_train_originX.shape)\n",
    "print(\"svd를 하지 않은 테스트 독립변수의 shape : \",X_test_originX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainX, X_testX, y_trainX, y_testX = train_test_split(X_train_originX, y_train_origin, test_size=0.3,random_state=100, stratify=y_train_origin)\n",
    "\n",
    "model_xgb_X = XGBClassifier(n_estimators=100,\n",
    "                            max_depth = 6,\n",
    "                            grow_policy='lossguide',\n",
    "                            learning_rate=0.5,\n",
    "                            min_child_weight=1,\n",
    "                            reg_lambda=1)\n",
    "xgb_model_X = model_xgb_X.fit(X_trainX, y_trainX)\n",
    "\n",
    "y_pred_X = xgb_model_X.predict(X_testX)\n",
    "# y_pred_prob = xgb_model.predict_proba(X_test)[:1]\n",
    "print(\"정확도 : \",accuracy_score(y_testX, y_pred_X))\n",
    "print(\"f1 socre : \",f1_score(y_testX, y_pred_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치를 채우지 않은 상태로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_origin2 = df_new.iloc[:301,2:]\n",
    "X_test_origin2 = df_new.iloc[301:, 2:]\n",
    "y_train_origin2 = df_new.iloc[:301,1]\n",
    "y_test_origin2 = df_new.iloc[301:,1]\n",
    "\n",
    "print(\"학습용 독립변수의 shape : \",X_train_origin2.shape)\n",
    "print(\"테스트 독립변수의 shape : \",X_test_origin2.shape)\n",
    "print(\"학습용 종속변수의 shape : \",y_train_origin2.shape)\n",
    "print(\"테스트 종속변수의 shape : \",y_test_origin2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train_origin2, y_train_origin2, test_size=0.2,random_state=100, stratify=y_train_origin2)\n",
    "\n",
    "model_xgb_2 = XGBClassifier(n_estimators=100,\n",
    "                            max_depth = 6,\n",
    "                            grow_policy='lossguide',\n",
    "                            learning_rate=0.5,\n",
    "                            min_child_weight=1,\n",
    "                            reg_lambda=1)\n",
    "xgb_model_2 = model_xgb_2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred_2 = xgb_model_2.predict(X_test2)\n",
    "# y_pred_prob = xgb_model.predict_proba(X_test)[:1]\n",
    "print(\"정확도 : \",accuracy_score(y_test2, y_pred_2))\n",
    "print(\"f1 socre : \",f1_score(y_test2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 병원 정보 api 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://apis.data.go.kr/B551182/hospInfoServicev2/getHospBasisList?serviceKey=repbMvjCXw96iTs6wjKM3Htm1H480VcdawruKmikMmOYZF8aVD%2FrJDkfGoyLeTuS5Y1KEOzUrwwPIu87UQ9LbQ%3D%3D&pageNo=1&numOfRows=10&sidoCd=110000&sgguCd=110019&emdongNm=%EC%8B%A0%EB%82%B4%EB%8F%99&yadmNm=%EC%84%9C%EC%9A%B8%EC%9D%98%EB%A3%8C%EC%9B%90&zipCd=2010&clCd=11&dgsbjtCd=01&xPos=127.09854004628151&yPos=37.6132113197367&radius=3000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceKey = \"repbMvjCXw96iTs6wjKM3Htm1H480VcdawruKmikMmOYZF8aVD/rJDkfGoyLeTuS5Y1KEOzUrwwPIu87UQ9LbQ==\"\n",
    "serviceKeyDecoded = parse.unquote(serviceKey, 'UTF-8')\n",
    "\n",
    "url = \"http://apis.data.go.kr/B551182/hospInfoServicev2/getHospBasisList\"\n",
    "returnType=\"xml\"\n",
    "Pindex = 1\n",
    "Psize = 1000\n",
    "\n",
    "\n",
    "queryParams = '?' + parse.urlencode({ parse.quote_plus(\"serviceKey\") : serviceKeyDecoded,\n",
    "                                parse.quote_plus(\"numOfRows\") : '10000',\n",
    "                                parse.quote_plus(\"pageNo\") : '2'\n",
    "                                    })\n",
    "\n",
    "res = requests.get(url + queryParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'lxml-xml')\n",
    "items = soup.find_all(\"item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    try:\n",
    "        ADDR = item.find(\"addr\").get_text()\n",
    "        CLCD = item.find(\"clCd\").get_text()\n",
    "        CLCDNM = item.find(\"clCdNm\").get_text()\n",
    "        EMDONGNM = item.find(\"emdongNm\").get_text()\n",
    "        ESTBDB = item.find(\"estbDd\").get_text()\n",
    "        POSTNO = item.find(\"postNo\").get_text()\n",
    "        SGGUCD = item.find(\"sgguCd\").get_text()\n",
    "        SGGUCDNM = item.find(\"sgguCdNm\").get_text()\n",
    "        SIDOCD = item.find(\"sidoCd\").get_text()\n",
    "        SIDOCDNM = item.find(\"sidoCdNm\").get_text()\n",
    "        XPOS = item.find(\"XPos\").get_text()\n",
    "        YPOS = item.find(\"YPos\").get_text()\n",
    "        YADMNM = item.find(\"yadmNm\").get_text()\n",
    "        YKIHO = item.find(\"ykiho\").get_text()\n",
    "        return {\n",
    "            \"주소\":ADDR,\n",
    "            \"종별코드\":CLCD,\n",
    "            \"종별코드명\":CLCDNM,\n",
    "            \"읍면동\":EMDONGNM,\n",
    "            \"개설일자\":ESTBDB,\n",
    "            \"Post No.\":POSTNO,\n",
    "            \"시군구코드\":SGGUCD,\n",
    "            \"시군구코드명\":SGGUCDNM,\n",
    "            \"시도코드\":SIDOCD,\n",
    "            \"시도코드명\":SIDOCDNM,\n",
    "            \"x좌표\":XPOS,\n",
    "            'y좌표':YPOS,\n",
    "            \"요양기관명\":YADMNM,\n",
    "            \"암호화요양기호\":YKIHO\n",
    "        }\n",
    "    except AttributeError as e:\n",
    "        return {\n",
    "            \"주소\":None,\n",
    "            \"종별코드\":None,\n",
    "            \"종별코드명\":None,\n",
    "            \"읍면동\":None,\n",
    "            \"개설일자\":None,\n",
    "            \"Post No.\":None,\n",
    "            \"시군구코드\":None,\n",
    "            \"시군구코드명\":None,\n",
    "            \"시도코드\":None,\n",
    "            \"시도코드명\":None,\n",
    "            \"x좌표\":None,\n",
    "            'y좌표':None,\n",
    "            \"요양기관명\":None,\n",
    "            \"암호화요양기호\":None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = list()\n",
    "\n",
    "for item in items : \n",
    "    row.append(parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = pd.DataFrame(row)\n",
    "df_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.shape[0] - df_api.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.dropna(axis=0, how=\"any\", inplace=True)\n",
    "df_api.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.to_csv(dirShare+\"/data/병원정보api_day2.csv\",sep=',', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day1  = pd.read_csv(dirShare+\"/data/병원정보api.csv\")\n",
    "df_day1.info()\n",
    "df_day1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day2  = pd.read_csv(dirShare+\"/data/병원정보api_day2.csv\")\n",
    "df_day2.info()\n",
    "df_day2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day1.sort_values(by='종별코드', axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day2.sort_values(by='종별코드', axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일부 컬럼을 추출해 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EVA논문 일부1](../data/EVA논문1_1.png)  \n",
    "![EVA논문 일부2](../data/EVA논문1_2.png)  \n",
    "\n",
    "이익잉여금은 기업의 경상적인 영업활동, 고정자산의 처분, 그 밖의 자산의 처분 및 기타 임시적인 손익거래에서 생긴 결과로서 주주에게 배당금으로 지급하거나 자본으로 대체되지 않고 남아있는 부분을 말한다. 이익잉여금은 기업의 경영활동에 의한 손익거래에 의하여 발생하는 이익을 원천으로 하는 잉여금을 의미한다. 이익잉여금은 이익준비금, 기타 법정적립금, 임의적립금, 당기말 미처분이익잉여금 또는 당기말 미처리결손금의 4가지로 크게 구분된다. 총자산에서 부채와 자본금을 공제한 잔액을 잉여금이라 하는데, 이익잉여금은 이익적립금ㆍ임의적립금(자산재평가적립금 제외) 또는 당기말 미처분이익잉여금과 같이 영업거래에서 발생하는 이익의 유보를 말하는 것으로 자본거래에서 나타나는(주식의 발행차금ㆍ감자차익ㆍ합병차익) 자본잉여금과는 다르다.  \n",
    "출처 : https://txsi.hometax.go.kr/docs/customer/dictionary/view.jsp?word=&word_id=7243  \n",
    "\n",
    "자기자본(Owners' Equity, Owner's Capital)\n",
    "기업의 총자본에서 차입자본금(부채)를 뺀 금액으로, 미래 일정 시점에 상환해야 할 의무가 없는 기업 고유의 재산이다. 소유주에게 귀속되어야 할 몫을 나타내기 때문에 소유주지분 또는 주주지분이라고도 불린다. 회사의 설립 때 납입된 자본과 영업활동을 하면서 벌어들인 이익 등으로 구성된다. 자기자본은 구체적 구성항목은 자본금ㆍ자본잉여금ㆍ주식발행초과금ㆍ기타포괄손익누계액ㆍ이익잉여금이며, 여기서의 자본금은 주주들이 현금이나 기타자산으로 직접 투자한 자본 중 주식의 액면가액에 해당되는 금액을 의미하며 납입자본(contributed capital)이라 불리기도 한다.  \n",
    "출처 : https://www.moef.go.kr/sisa/dictionary/detail?idx=2098  \n",
    "\n",
    "EVA는 기업의 고유한 영업호라동을 통해 창출된 순가치의 증가분으로, 세후 영업이익에서 투하 자본에 대한 자본 비용이 공제된 잔여이익\n",
    "EVA = 세후순영업이익 - 자본비용  \n",
    "    = (영업관련 경상이익-법인세) - (타인자본비용+자기자본비용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_prepro(dataframe=None, df_pop=None) : \n",
    "    \"\"\"\n",
    "    가장 기본이 되는 데이터프레임에서\n",
    "    새로운 데이터프레임을 만들 때\n",
    "    그 이후 전처리를 수행하는 함수입니다.\n",
    "\n",
    "    일부 추출한 데이터 프레임 : dataframe\n",
    "    join할 인구 수 데이터 프레임 : df_pop\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = pd.get_dummies(dataframe, columns=[\"instkind\"], prefix=[\"instkind\"], prefix_sep=\"_\", dtype=int)\n",
    "    dataframe[\"sido\"].replace(['choongnam', 'gyeongnam', 'gyeonggi', 'incheon', 'busan',\n",
    "       'jeonnam', 'seoul', 'jeonbuk', 'choongbuk', 'ulsan', 'daejeon',\n",
    "       'daegu', 'gyeongbuk', 'gangwon', 'gwangju', 'sejong', 'jeju'], \n",
    "       [\"충청남도\", \"경상남도\", \"경기도\", \"인천광역시\", '부산광역시', '전라남도', '서울특별시', \n",
    "        '전라북도', '충청북도', '울산광역시', '대전광역시', '대구광역시', \"경상북도\", \"강원도\", \"광주광역시\", \"세종특별자치시\", '제주특별자치도'],inplace=True)\n",
    "    dataframe = pd.merge(dataframe, df_pop, how=\"inner\", left_on=\"sido\", right_on=\"행정구역(시군구)별\")\n",
    "    dataframe = pd.get_dummies(dataframe, columns=[\"sido\"], prefix=[\"sido\"], prefix_sep=\"_\", dtype=int)\n",
    "    dataframe.drop(columns=\"행정구역(시군구)별\", axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clst = df_merge[[\"inst_id\",\"OC\", \"dif_date\",\"bedCount\",\"busiProfit1\", \"busiProfit2\", \"profit1\", \"surplus1\", \"profit2\", \"surplus2\", \n",
    "                  \"employee1\", \"employee2\",\"instkind\", \"sido\"]]\n",
    "\n",
    "df_clst.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clst = same_prepro(df_clst, df_pop=pop)\n",
    "df_clst.info()\n",
    "df_clst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_kmeans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans.groupby(by=\"NumberOfCluster\", axis=0)[\"inst_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_clst[df_join_clst.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_join_clst[df_join_clst.notnull().all(axis=1)].groupby(\"NumberOfCluster\", axis=0).max()\n",
    "df_join_clst.groupby(\"NumberOfCluster\", axis=0).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clst_median = df_join_clst.groupby(\"NumberOfCluster\", axis=0).median()\n",
    "df_clst_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17년도 당기순이익 히스토그램\n",
    "sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"profit1\", Range=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17년도 당기순이익 박스플롯\n",
    "sp_boxplot(DF=df_join_clst, colClst=\"NumberOfCluster\", colbox=\"profit1\", Range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[test_df[\"1\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16년도 당기순이익\n",
    "# sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"profit2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17년도 이익 잉여금\n",
    "# sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"surplus1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16년도 이익 잉여금\n",
    "# sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"surplus2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17년도 직원수\n",
    "# sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"employee1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16년도 직원수\n",
    "# sp_hist(DF=df_join_clst, colClst=\"NumberOfCluster\", colhist=\"employee2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 당기순이익 : 중앙값\n",
    "- 이익잉여금 : 중앙값\n",
    "- 직원 수 : 16년도와 17년도의 중앙값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
